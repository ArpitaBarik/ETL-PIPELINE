{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe1f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import polars as pl\n",
    "import pymysql\n",
    "from polars import LazyFrame\n",
    "\n",
    "# --- 1. Configuration and Setup ---\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('bank_etl_pipeline_polars.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fd3339",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"Barik@1010arpita\", \n",
    "    \"database\": \"bank_monitoring_db\",\n",
    "    \"port\": 3306,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3681169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Schema Definition (Polars Style) ---\n",
    "\n",
    "def define_accounts_schema() -> Dict[str, pl.DataType]:\n",
    "    \"\"\"Defines the schema for the accounts data using Polars dtypes.\"\"\"\n",
    "    return {\n",
    "        \"cust_id\": pl.String,\n",
    "        \"account_number\": pl.String,\n",
    "        \"name\": pl.String,\n",
    "        \"acc_type\": pl.String,\n",
    "        \"opened_date\": pl.String\n",
    "    }\n",
    "\n",
    "def define_transactions_schema() -> Dict[str, pl.DataType]:\n",
    "    \"\"\"Defines the schema for the transactions data using Polars dtypes.\"\"\"\n",
    "    return {\n",
    "        \"txn_id\": pl.String,\n",
    "        \"source_acc_number\": pl.String,\n",
    "        \"target_acc_number\": pl.String,\n",
    "        \"source_account_debit\": pl.Decimal(precision=15, scale=2),\n",
    "        \"target_account_credit\": pl.Decimal(precision=15, scale=2),\n",
    "        \"txn_amount\": pl.Decimal(precision=15, scale=2),\n",
    "        \"transaction_date\": pl.String,\n",
    "        \"source_acc_type\": pl.String\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2ed86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Extract Phase ---\n",
    "\n",
    "def read_accounts_data(file_path: str) -> LazyFrame:\n",
    "    \"\"\"Lazily read accounts CSV data from the specified file path using Polars.\"\"\"\n",
    "    try:\n",
    "        # MODIFIED: Used schema_overrides instead of the deprecated dtypes\n",
    "        lf = pl.scan_csv(file_path, schema_overrides=define_accounts_schema())\n",
    "\n",
    "        # Filter out completely empty rows\n",
    "        lf = lf.filter(\n",
    "            ~((pl.col(\"cust_id\").is_null()) &\n",
    "              (pl.col(\"account_number\").is_null()) &\n",
    "              (pl.col(\"name\").is_null()))\n",
    "        )\n",
    "        logger.info(f\"Successfully planned reading of accounts from {file_path}\")\n",
    "        return lf\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read accounts CSV data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def read_transactions_data(file_path: str) -> LazyFrame:\n",
    "    \"\"\"Lazily read transactions CSV data from the specified file path using Polars.\"\"\"\n",
    "    try:\n",
    "        # MODIFIED: Used schema_overrides instead of the deprecated dtypes\n",
    "        lf = pl.scan_csv(file_path, schema_overrides=define_transactions_schema())\n",
    "\n",
    "        # Filter out completely empty rows\n",
    "        lf = lf.filter(\n",
    "            ~((pl.col(\"txn_id\").is_null()) &\n",
    "              (pl.col(\"source_acc_number\").is_null()) &\n",
    "              (pl.col(\"target_acc_number\").is_null()))\n",
    "        )\n",
    "        logger.info(f\"Successfully planned reading of transactions from {file_path}\")\n",
    "        return lf\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read transactions CSV data: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16aa71c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Transform (Validation) Phase ---\n",
    "\n",
    "def validate_accounts(accounts_lf: LazyFrame) -> Tuple[LazyFrame, LazyFrame]:\n",
    "    \"\"\"Validate accounts data and separate valid from invalid records using Polars.\"\"\"\n",
    "    try:\n",
    "        # Find duplicate account numbers\n",
    "        duplicate_accounts_df = accounts_lf.group_by(\"account_number\").agg(\n",
    "            # MODIFIED: Used pl.len() instead of the deprecated pl.count()\n",
    "            pl.len().alias(\"count\")\n",
    "        ).filter(pl.col(\"count\") > 1).collect()\n",
    "        duplicate_account_numbers = duplicate_accounts_df[\"account_number\"]\n",
    "\n",
    "        # Add validation reason column\n",
    "        accounts_with_reason = accounts_lf.with_columns(\n",
    "            invalid_reason=pl.when(\n",
    "                (pl.col(\"cust_id\").is_null() | (pl.col(\"cust_id\") == \"\")) |\n",
    "                (pl.col(\"account_number\").is_null() | (pl.col(\"account_number\") == \"\")) |\n",
    "                (pl.col(\"name\").is_null() | (pl.col(\"name\") == \"\")) |\n",
    "                (pl.col(\"acc_type\").is_null() | (pl.col(\"acc_type\") == \"\")) |\n",
    "                (pl.col(\"opened_date\").is_null() | (pl.col(\"opened_date\") == \"\"))\n",
    "            ).then(pl.lit(\"Null values found in required fields\"))\n",
    "            .when(pl.col(\"account_number\").is_in(duplicate_account_numbers))\n",
    "            .then(pl.lit(\"Duplicate account number\"))\n",
    "            .otherwise(pl.lit(None))\n",
    "        )\n",
    "\n",
    "        # Separate valid and invalid records\n",
    "        valid_accounts = accounts_with_reason.filter(pl.col(\"invalid_reason\").is_null())\n",
    "        invalid_accounts = accounts_with_reason.filter(pl.col(\"invalid_reason\").is_not_null())\n",
    "\n",
    "        logger.info(\"Account validation plan created.\")\n",
    "        return valid_accounts, invalid_accounts\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to validate accounts: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_transactions(transactions_lf: LazyFrame, valid_accounts_lf: LazyFrame) -> Tuple[LazyFrame, LazyFrame]:\n",
    "    \"\"\"Validate transactions data and separate valid from invalid records using Polars.\"\"\"\n",
    "    try:\n",
    "        # Get list of valid account numbers\n",
    "        valid_account_numbers = valid_accounts_lf.select(\"account_number\").collect().to_series()\n",
    "\n",
    "        # Check for duplicate transactions\n",
    "        duplicate_txn_df = transactions_lf.group_by(\"txn_id\").agg(\n",
    "            # MODIFIED: Used pl.len() instead of the deprecated pl.count()\n",
    "            pl.len().alias(\"count\")\n",
    "        ).filter(pl.col(\"count\") > 1).collect()\n",
    "        duplicate_txn_ids = duplicate_txn_df[\"txn_id\"]\n",
    "\n",
    "        # Add validation reason column\n",
    "        transactions_with_reason = transactions_lf.with_columns(\n",
    "            invalid_reason=pl.when(pl.col(\"txn_amount\") > 50000)\n",
    "            .then(pl.lit(\"High-value transaction (>50,000)\"))\n",
    "            .when(pl.col(\"source_acc_type\") == \"loan\")\n",
    "            .then(pl.lit(\"Invalid source account type (loan)\"))\n",
    "            .when(\n",
    "                (pl.col(\"txn_id\").is_null() | (pl.col(\"txn_id\") == \"\")) |\n",
    "                (pl.col(\"source_acc_number\").is_null() | (pl.col(\"source_acc_number\") == \"\")) |\n",
    "                (pl.col(\"target_acc_number\").is_null() | (pl.col(\"target_acc_number\") == \"\")) |\n",
    "                pl.col(\"source_account_debit\").is_null() |\n",
    "                pl.col(\"target_account_credit\").is_null() |\n",
    "                pl.col(\"txn_amount\").is_null() |\n",
    "                (pl.col(\"transaction_date\").is_null() | (pl.col(\"transaction_date\") == \"\")) |\n",
    "                (pl.col(\"source_acc_type\").is_null() | (pl.col(\"source_acc_type\") == \"\"))\n",
    "            ).then(pl.lit(\"Null values found in required fields\"))\n",
    "            .when(\n",
    "                (pl.col(\"txn_amount\") != pl.col(\"source_account_debit\")) |\n",
    "                (pl.col(\"txn_amount\") != pl.col(\"target_account_credit\")) |\n",
    "                (pl.col(\"source_account_debit\") != pl.col(\"target_account_credit\"))\n",
    "            ).then(pl.lit(\"Mismatched transaction amounts\"))\n",
    "            .when(\n",
    "                ~pl.col(\"source_acc_number\").is_in(valid_account_numbers) |\n",
    "                ~pl.col(\"target_acc_number\").is_in(valid_account_numbers)\n",
    "            ).then(pl.lit(\"Orphan accounts (not found in accounts file)\"))\n",
    "            .when(pl.col(\"txn_id\").is_in(duplicate_txn_ids))\n",
    "            .then(pl.lit(\"Duplicate transaction ID\"))\n",
    "            .otherwise(pl.lit(None))\n",
    "        )\n",
    "\n",
    "        # Separate valid and invalid records\n",
    "        valid_transactions = transactions_with_reason.filter(pl.col(\"invalid_reason\").is_null())\n",
    "        invalid_transactions = transactions_with_reason.filter(pl.col(\"invalid_reason\").is_not_null())\n",
    "\n",
    "        logger.info(\"Transaction validation plan created.\")\n",
    "        return valid_transactions, invalid_transactions\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to validate transactions: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a86fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Load Phase ---\n",
    "\n",
    "def create_database_tables():\n",
    "    \"\"\"Create the required MySQL tables.\"\"\"\n",
    "    # This function would contain the pymysql code to create tables if they don't exist.\n",
    "    # For this example, we assume tables are already created.\n",
    "    logger.info(\"Database table creation check complete.\")\n",
    "    pass\n",
    "\n",
    "from urllib.parse import quote_plus # Add this import at the top of your script\n",
    "\n",
    "def load_to_database(df: pl.DataFrame, table_name: str) -> None:\n",
    "    \"\"\"Load a Polars DataFrame to a MySQL database.\"\"\"\n",
    "    try:\n",
    "        # --- SOLUTION: URL-encode the password to handle special characters ---\n",
    "        safe_password = quote_plus(DATABASE_CONFIG['password'])\n",
    "\n",
    "        # Use the new safe_password to build the connection URI\n",
    "        db_uri = (\n",
    "            f\"mysql+pymysql://{DATABASE_CONFIG['user']}:{safe_password}\"\n",
    "            f\"@{DATABASE_CONFIG['host']}:{DATABASE_CONFIG['port']}/{DATABASE_CONFIG['database']}\"\n",
    "        )\n",
    "\n",
    "        df_with_timestamp = df.with_columns(created_at=datetime.now())\n",
    "        \n",
    "        df_with_timestamp.write_database(\n",
    "            table_name=table_name,\n",
    "            connection=db_uri,\n",
    "            if_table_exists=\"append\"\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Successfully loaded {len(df)} records to {table_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load data to database table {table_name}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb99434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 12:49:52,553 - __main__ - INFO - Starting Bank Transaction Monitoring ETL Pipeline with Polars\n",
      "2025-10-18 12:49:52,554 - __main__ - INFO - Step 1: Planning to read CSV files\n",
      "2025-10-18 12:49:52,556 - __main__ - INFO - Successfully planned reading of accounts from c:/Users/ARPITA/Downloads/accounts.csv\n",
      "2025-10-18 12:49:52,559 - __main__ - INFO - Successfully planned reading of transactions from c:/Users/ARPITA/Downloads/transactions.csv\n",
      "2025-10-18 12:49:52,560 - __main__ - INFO - Step 2a: Planning accounts data validation\n",
      "2025-10-18 12:49:52,599 - __main__ - INFO - Account validation plan created.\n",
      "2025-10-18 12:49:52,600 - __main__ - INFO - Step 2b: Planning transactions data validation\n",
      "C:\\Users\\ARPITA\\AppData\\Local\\Temp\\ipykernel_15116\\1962940419.py:41: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  valid_account_numbers = valid_accounts_lf.select(\"account_number\").collect().to_series()\n",
      "2025-10-18 12:49:52,629 - __main__ - INFO - Transaction validation plan created.\n",
      "2025-10-18 12:49:52,630 - __main__ - INFO - Executing transformation plans...\n",
      "C:\\Users\\ARPITA\\AppData\\Local\\Temp\\ipykernel_15116\\3847304430.py:28: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  invalid_accounts_final = invalid_accounts.collect()\n",
      "C:\\Users\\ARPITA\\AppData\\Local\\Temp\\ipykernel_15116\\3847304430.py:29: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  invalid_transactions_final = invalid_transactions.collect()\n",
      "C:\\Users\\ARPITA\\AppData\\Local\\Temp\\ipykernel_15116\\3847304430.py:30: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  valid_transactions_final = valid_transactions.collect()\n",
      "C:\\Users\\ARPITA\\AppData\\Local\\Temp\\ipykernel_15116\\3847304430.py:31: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  valid_accounts_final = valid_accounts.collect()\n",
      "2025-10-18 12:49:52,642 - __main__ - INFO - Step 3: Loading data to database\n",
      "2025-10-18 12:49:52,643 - __main__ - INFO - Database table creation check complete.\n",
      "2025-10-18 12:49:52,943 - numexpr.utils - INFO - NumExpr defaulting to 12 threads.\n",
      "2025-10-18 12:49:53,593 - __main__ - INFO - Successfully loaded 19 records to invalid_account\n",
      "2025-10-18 12:49:53,643 - __main__ - INFO - Successfully loaded 407 records to invalid_transactions\n",
      "2025-10-18 12:49:53,697 - __main__ - INFO - Successfully loaded 893 records to valid_transactions\n",
      "2025-10-18 12:49:53,698 - __main__ - INFO - ETL Pipeline completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bank Transaction Monitoring ETL Pipeline Summary ===\n",
      "Total accounts processed: 404\n",
      "Valid accounts: 385\n",
      "Invalid accounts: 19\n",
      "\n",
      "Total transactions processed: 1300\n",
      "Valid transactions: 893\n",
      "Invalid transactions: 407\n",
      "\n",
      "Account success rate: 95.30%\n",
      "Transaction success rate: 68.69%\n",
      "\n",
      "=== Sample Invalid Accounts ===\n",
      "shape: (5, 3)\n",
      "┌────────────────┬───────────────┬──────────────────────────┐\n",
      "│ account_number ┆ name          ┆ invalid_reason           │\n",
      "│ ---            ┆ ---           ┆ ---                      │\n",
      "│ str            ┆ str           ┆ str                      │\n",
      "╞════════════════╪═══════════════╪══════════════════════════╡\n",
      "│ ACC100001      ┆ Lisa Shaw     ┆ Duplicate account number │\n",
      "│ ACC100001      ┆ Ben Shaw      ┆ Duplicate account number │\n",
      "│ ACC100010      ┆ Ben Duckett   ┆ Duplicate account number │\n",
      "│ ACC100010      ┆ Cody Shepherd ┆ Duplicate account number │\n",
      "│ ACC100018      ┆ Howard Wilson ┆ Duplicate account number │\n",
      "└────────────────┴───────────────┴──────────────────────────┘\n",
      "\n",
      "=== Sample Invalid Transactions ===\n",
      "shape: (5, 4)\n",
      "┌──────────────┬───────────────────┬───────────────────┬─────────────────────────────────┐\n",
      "│ txn_id       ┆ source_acc_number ┆ target_acc_number ┆ invalid_reason                  │\n",
      "│ ---          ┆ ---               ┆ ---               ┆ ---                             │\n",
      "│ str          ┆ str               ┆ str               ┆ str                             │\n",
      "╞══════════════╪═══════════════════╪═══════════════════╪═════════════════════════════════╡\n",
      "│ BNQS3QT36QNY ┆ ACC100257         ┆ ACC100348         ┆ High-value transaction (>50,00… │\n",
      "│ G8CFEFFH8AOY ┆ ACC100044         ┆ ACC100041         ┆ Mismatched transaction amounts  │\n",
      "│ C5I8XOMXLVZ4 ┆ ACC100330         ┆ ACC100010         ┆ Orphan accounts (not found in … │\n",
      "│ L2INK4FK8WFT ┆ ACC100290         ┆ ACC100067         ┆ High-value transaction (>50,00… │\n",
      "│ 2FE9UPNHZX9F ┆ ACC100362         ┆ ACC200547         ┆ High-value transaction (>50,00… │\n",
      "└──────────────┴───────────────────┴───────────────────┴─────────────────────────────────┘\n",
      "\n",
      "=== Sample Valid Transactions ===\n",
      "shape: (5, 9)\n",
      "┌──────────┬──────────┬──────────┬──────────┬──────────┬──────────┬──────────┬──────────┬──────────┐\n",
      "│ txn_id   ┆ source_a ┆ target_a ┆ source_a ┆ target_a ┆ txn_amou ┆ transact ┆ source_a ┆ invalid_ │\n",
      "│ ---      ┆ cc_numbe ┆ cc_numbe ┆ ccount_d ┆ ccount_c ┆ nt       ┆ ion_date ┆ cc_type  ┆ reason   │\n",
      "│ str      ┆ r        ┆ r        ┆ ebit     ┆ redit    ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
      "│          ┆ ---      ┆ ---      ┆ ---      ┆ ---      ┆ decimal[ ┆ str      ┆ str      ┆ str      │\n",
      "│          ┆ str      ┆ str      ┆ decimal[ ┆ decimal[ ┆ 15,2]    ┆          ┆          ┆          │\n",
      "│          ┆          ┆          ┆ 15,2]    ┆ 15,2]    ┆          ┆          ┆          ┆          │\n",
      "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ HYWM7S6N ┆ ACC10031 ┆ ACC10027 ┆ 34556.24 ┆ 34556.24 ┆ 34556.24 ┆ 02-04-20 ┆ salary   ┆ null     │\n",
      "│ BNQB     ┆ 3        ┆ 7        ┆          ┆          ┆          ┆ 25       ┆          ┆          │\n",
      "│ ZH9IER7U ┆ ACC10028 ┆ ACC10036 ┆ 4113.65  ┆ 4113.65  ┆ 4113.65  ┆ 05-11-20 ┆ salary   ┆ null     │\n",
      "│ 8H0I     ┆ 6        ┆ 0        ┆          ┆          ┆          ┆ 24       ┆          ┆          │\n",
      "│ 1HD4Y89O ┆ ACC10026 ┆ ACC10011 ┆ 46898.87 ┆ 46898.87 ┆ 46898.87 ┆ 12-07-20 ┆ business ┆ null     │\n",
      "│ RVSC     ┆ 9        ┆ 3        ┆          ┆          ┆          ┆ 24       ┆          ┆          │\n",
      "│ 0AJUFQYM ┆ ACC10035 ┆ ACC10006 ┆ 22454.81 ┆ 22454.81 ┆ 22454.81 ┆ 24-07-20 ┆ savings  ┆ null     │\n",
      "│ BNW8     ┆ 5        ┆ 1        ┆          ┆          ┆          ┆ 24       ┆          ┆          │\n",
      "│ SNRM6DFH ┆ ACC10018 ┆ ACC10007 ┆ 872.57   ┆ 872.57   ┆ 872.57   ┆ 05-03-20 ┆ business ┆ null     │\n",
      "│ G6W3     ┆ 0        ┆ 3        ┆          ┆          ┆          ┆ 25       ┆          ┆          │\n",
      "└──────────┴──────────┴──────────┴──────────┴──────────┴──────────┴──────────┴──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Main ETL Pipeline Execution ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main ETL pipeline execution function.\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting Bank Transaction Monitoring ETL Pipeline with Polars\")\n",
    "\n",
    "        # Configuration\n",
    "        accounts_file_path = \"c:/Users/ARPITA/Downloads/accounts.csv\"\n",
    "        transactions_file_path = \"c:/Users/ARPITA/Downloads/transactions.csv\"\n",
    "\n",
    "        # Step 1: Extract (lazily)\n",
    "        logger.info(\"Step 1: Planning to read CSV files\")\n",
    "        accounts_lf = read_accounts_data(accounts_file_path)\n",
    "        transactions_lf = read_transactions_data(transactions_file_path)\n",
    "\n",
    "        # Step 2: Transform (Validate)\n",
    "        logger.info(\"Step 2a: Planning accounts data validation\")\n",
    "        valid_accounts, invalid_accounts = validate_accounts(accounts_lf)\n",
    "\n",
    "        logger.info(\"Step 2b: Planning transactions data validation\")\n",
    "        valid_transactions, invalid_transactions = validate_transactions(transactions_lf, valid_accounts)\n",
    "\n",
    "        # --- EXECUTION TRIGGER (.collect()) ---\n",
    "        logger.info(\"Executing transformation plans...\")\n",
    "        \n",
    "        # Collect final dataframes\n",
    "        invalid_accounts_final = invalid_accounts.collect()\n",
    "        invalid_transactions_final = invalid_transactions.collect()\n",
    "        valid_transactions_final = valid_transactions.collect()\n",
    "        valid_accounts_final = valid_accounts.collect()\n",
    "        \n",
    "        # Step 3: Load\n",
    "        logger.info(\"Step 3: Loading data to database\")\n",
    "        create_database_tables() # Ensure tables exist\n",
    "\n",
    "        if not invalid_accounts_final.is_empty():\n",
    "            load_to_database(invalid_accounts_final.select(pl.exclude(\"invalid_reason\")), \"invalid_account\")\n",
    "\n",
    "        if not invalid_transactions_final.is_empty():\n",
    "            load_to_database(invalid_transactions_final.select(pl.exclude(\"invalid_reason\")), \"invalid_transactions\")\n",
    "\n",
    "        if not valid_transactions_final.is_empty():\n",
    "            load_to_database(valid_transactions_final.select(pl.exclude(\"invalid_reason\")), \"valid_transactions\")\n",
    "\n",
    "        logger.info(\"ETL Pipeline completed successfully\")\n",
    "        \n",
    "        # --- Summary ---\n",
    "        total_accounts = accounts_lf.collect().height\n",
    "        total_transactions = transactions_lf.collect().height\n",
    "        valid_accounts_count = valid_accounts_final.height\n",
    "        valid_transactions_count = valid_transactions_final.height\n",
    "        invalid_accounts_count = invalid_accounts_final.height\n",
    "        invalid_transactions_count = invalid_transactions_final.height\n",
    "\n",
    "        print(f\"\\n=== Bank Transaction Monitoring ETL Pipeline Summary ===\")\n",
    "        print(f\"Total accounts processed: {total_accounts}\")\n",
    "        print(f\"Valid accounts: {valid_accounts_count}\")\n",
    "        print(f\"Invalid accounts: {invalid_accounts_count}\")\n",
    "        print(f\"\")\n",
    "        print(f\"Total transactions processed: {total_transactions}\")\n",
    "        print(f\"Valid transactions: {valid_transactions_count}\")\n",
    "        print(f\"Invalid transactions: {invalid_transactions_count}\")\n",
    "        print(f\"\")\n",
    "        if total_accounts > 0:\n",
    "            print(f\"Account success rate: {(valid_accounts_count/total_accounts)*100:.2f}%\")\n",
    "        if total_transactions > 0:\n",
    "            print(f\"Transaction success rate: {(valid_transactions_count/total_transactions)*100:.2f}%\")\n",
    "\n",
    "        # Show sample data\n",
    "        print(f\"\\n=== Sample Invalid Accounts ===\")\n",
    "        print(invalid_accounts_final.select(\"account_number\", \"name\", \"invalid_reason\").head(5))\n",
    "\n",
    "        print(f\"\\n=== Sample Invalid Transactions ===\")\n",
    "        print(invalid_transactions_final.select(\"txn_id\", \"source_acc_number\", \"target_acc_number\", \"invalid_reason\").head(5))\n",
    "\n",
    "        print(f\"\\n=== Sample Valid Transactions ===\")\n",
    "        print(valid_transactions_final.head(5))\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ETL Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # To prevent issues with long tracebacks on display, configure Polars\n",
    "    pl.Config.set_tbl_rows(10)\n",
    "    pl.Config.set_tbl_cols(10)\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
